# ============================================================
# AI Software Factory — Environment Variables
# Copy this file to .env and fill in all REQUIRED values.
# NEVER commit .env to version control.
# ============================================================

# ---- LLM API Keys (REQUIRED) --------------------------------
XAI_API_KEY=xai-                          # xAI key for grok-4 / grok-4.1-fast
ANTHROPIC_API_KEY=sk-ant-                 # Anthropic key for claude-opus-4.6
OPENAI_API_KEY=sk-                        # OpenAI key for gpt-5-mini (factory/cheap)

# ---- Search & Scraping (REQUIRED for BizAnalysis, ProductMgmt) --
TAVILY_API_KEY=tvly-
FIRECRAWL_API_KEY=fc-

# ---- Code Execution Sandbox (REQUIRED for coding squads) -----
E2B_API_KEY=e2b_

# ---- Version Control -----------------------------------------
GITHUB_TOKEN=ghp_                         # PAT with repo + workflow scopes
GITHUB_ORG=your-org
GITHUB_REPO=factory-output               # Target repo for generated artifacts

# ---- PostgreSQL (direct — migrations only) -------------------
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=factory
POSTGRES_USER=factory_user
POSTGRES_PASSWORD=CHANGEME               # Change this in production

# ---- PgBouncer (ALL services use this, NEVER direct Postgres) --
PGBOUNCER_HOST=pgbouncer
PGBOUNCER_PORT=6432
PGBOUNCER_POOL_MODE=transaction          # MUST be transaction mode
PGBOUNCER_MAX_CLIENT_CONN=100
PGBOUNCER_DEFAULT_POOL_SIZE=20

# ---- Redis ---------------------------------------------------
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=                          # Empty for local dev
REDIS_STREAM_MAXLEN=10000

# ---- Ollama (replaces LM Studio — concurrent-request capable) --
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_CONCURRENT_REQUESTS=4
OLLAMA_MODEL_CODER=qwen2.5-coder:32b
OLLAMA_MODEL_ARCHITECT=llama3.3:70b
OLLAMA_MODEL_FAST=llama3.2:3b
OLLAMA_MODEL_EMBED=nomic-embed-text

# ---- LiteLLM -------------------------------------------------
# Phase 1: SDK mode (LITELLM_PROXY_URL not used)
# Phase 2: enable proxy with PgBouncer
LITELLM_MASTER_KEY=sk-factory-           # Phase 2 only
LITELLM_PROXY_URL=http://litellm-proxy:4000  # Phase 2 only
LITELLM_LOG_LEVEL=INFO

# ---- CrewAI (DO NOT change version without full regression) ---
CREWAI_VERSION_PIN=0.108.0               # EXACT semver — pin immediately
CREWAI_TELEMETRY_OPT_OUT=true
CREWAI_MAX_ITER=5                        # Override default 25 — prevents loops

# ---- Hindsight Memory Engine ---------------------------------
HINDSIGHT_DB_URL=postgresql+asyncpg://factory_user:CHANGEME@pgbouncer:6432/factory
HINDSIGHT_DEFAULT_BANK=factory-shared-world
HINDSIGHT_COMPRESSION_THRESHOLD=0.80    # Trigger at 80% of 128K
HINDSIGHT_EMBED_MODEL=nomic-embed-text

# ---- Mem0 (CrewAI native hook) -------------------------------
MEM0_CONFIG_PROVIDER=mem0
MEM0_LLM_MODEL=factory/cheap            # Cost-optimised extraction
MEM0_EMBED_MODEL=local/embed

# ---- Memvid (immutable audit log) ----------------------------
MEMVID_STORAGE_PATH=/data/memvid
MEMVID_HNSW_EF_SEARCH=50

# ---- Langfuse (ADD CALLBACKS BEFORE FEATURES — debug-first) --
LANGFUSE_PUBLIC_KEY=pk-lf-
LANGFUSE_SECRET_KEY=sk-lf-
LANGFUSE_HOST=http://langfuse-web:3010
LANGFUSE_ENABLED=true

# ---- Prometheus / Grafana ------------------------------------
PROMETHEUS_PORT=9090
GRAFANA_ADMIN_PASSWORD=CHANGEME
GRAFANA_PORT=3000

# ---- Loki / OTel / GlitchTip --------------------------------
LOKI_URL=http://loki:3100
OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
OTEL_SERVICE_NAME=factory-orchestrator  # Override per-service in compose
GLITCHTIP_DSN=
GLITCHTIP_ENABLED=false

# ---- Chainlit Chat Service -----------------------------------
CHAINLIT_AUTH_SECRET=CHANGEME
CHAINLIT_PORT=8001

# ---- React Dashboard -----------------------------------------
REACT_DASHBOARD_PORT=3001
VITE_API_BASE_URL=http://localhost:8000
VITE_WS_URL=ws://localhost:8000

# ---- Inter-Service Auth (shared secret) ----------------------
INTERNAL_SERVICE_TOKEN=CHANGEME

# ---- Internal service URLs -----------------------------------
MEMORY_SERVICE_URL=http://memory:8006

# ---- Clarification Protocol ----------------------------------
CLARIFICATION_TTL_SECONDS=120
CLARIFICATION_MAX_PER_TASK=3
CLARIFICATION_MAX_HOP_DEPTH=2
RESPONDER_TEAMS=biz_analysis,solution_arch,backend_eng,qa_eng,docs_team

# ---- HITL Service -------------------------------------------
HITL_MAX_QUEUE_DEPTH=10

# ---- E2B Sandbox Toggle (per-session override in dashboard) --
E2B_SANDBOX_ENABLED=true

# ---- Optional: Jira / Confluence (ProductMgmt, BizAnalysis) --
JIRA_BASE_URL=
JIRA_EMAIL=
JIRA_API_TOKEN=
CONFLUENCE_BASE_URL=
CONFLUENCE_API_TOKEN=

# ---- Optional: External Integrations -------------------------
FIGMA_ACCESS_TOKEN=         # UXUI squad
PAGERDUTY_API_KEY=          # SREOps squad
POSTMAN_API_KEY=             # APIDesign squad
WANDB_API_KEY=               # MLEng squad
MLFLOW_TRACKING_URI=http://localhost:5000
AIRFLOW_BASE_URL=http://localhost:8080
AIRFLOW_USERNAME=admin
AIRFLOW_PASSWORD=

# ---- SonarQube (optional --profile sonarqube) ----------------
SONAR_HOST_URL=http://sonarqube:9000
SONAR_TOKEN=

# ---- Feature Flags (flip to true as phases complete) ---------
ENABLE_AUTOGEN_GROUP_CHAT=false         # Phase 2
ENABLE_LITELLM_PROXY=false              # Phase 2
ENABLE_MENTAL_MODELS=false              # Phase 2
ENABLE_REACT_FLOW_GRAPH=false           # Phase 2
